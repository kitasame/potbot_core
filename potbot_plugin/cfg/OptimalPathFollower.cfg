#!/usr/bin/env python
PACKAGE = "potbot_plugin"

from dynamic_reconfigure.parameter_generator_catkin import *

gen = ParameterGenerator()

cns = gen.enum([gen.const("all_search", str_t, "all_search", "Use all_search"),
                gen.const("gradient", str_t, "gradient", "Use gradient")],
               "optimization_method names")
gen.add("optimization_method", str_t, 0, "Which name to use, all_search, gradient", "gradient", edit_method=cns)

gen.add("stop_margin_angle",                    double_t, 0, "A double parameter", 0.1, 0, 0.2)
gen.add("stop_margin_distance",                 double_t, 0, "A double parameter", 0.05, 0, 0.3)
gen.add("max_linear_velocity",          double_t, 0, "A double parameter", 0.5, 0, 2)
gen.add("min_linear_velocity",          double_t, 0, "A double parameter", -0.5, -2, 0)
gen.add("max_angular_velocity",         double_t, 0, "A double parameter", 1, 0, 3)
gen.add("min_angular_velocity",         double_t, 0, "A double parameter", -1, -3, 0)
gen.add("time_increment",           double_t, 0, "A double parameter", 0.1, 0.001, 1.0)
gen.add("time_end",           double_t, 0, "A double parameter", 1, 0.01, 10.0)
gen.add("linear_velocity_increment",double_t, 0, "A double parameter", 0.05, 0.001, 0.3)
gen.add("angular_velocity_increment",double_t, 0, "A double parameter", 0.1, 0.001, 1.0)
gen.add("max_iteration",int_t, 0, "for gradient optimization", 100, 1, 5000)
gen.add("learning_rate",double_t, 0, "for gradient optimization", 0.01, 0.0, 1)

exit(gen.generate(PACKAGE, "potbot_plugin", "OptimalPathFollower"))